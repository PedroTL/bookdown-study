---
title: "Bookdown - A Short Introduction to R"
author: "João Pedro"
date: "`r format(Sys.time(), '%d, %B, %Y')`"
output: 
  html_document:
    code_folding: hide
    keep_md: true
    css: styles.css
    toc: true
    toc_depth: 4
    theme: united
    highlight: tango
---
```{r}
library(knitr)
opts_knit$set(root.dir = "C:\\Users\\pedro\\Documents\\GitHub\\bookdown-study\\short-introduction-r\\data")
```

## 1. Nuts and Bolts

### 1.1 R Objects

R has five basic or “atomic” classes of objects:

- character
- numeric (real numbers)
- integer
- complex
- logical (True/False)

The most basic type of R object is a vector. Empty vectors can be created with the vector() function. There is really only one rule about vectors in R, which is that A vector can only contain objects of the same class.

But of course, like any good rule, there is an exception, which is a list, which we will get to a bit later. A list is represented as a vector but can contain objects of different classes. Indeed, that’s usually why we use them.

There is also a class for “raw” objects, but they are not commonly used directly in data analysis and I won’t cover them here.

### 1.2 Numbers

Numbers in R are generally treated as numeric objects (i.e. double precision real numbers). This means that even if you see a number like “1” or “2” in R, which you might think of as integers, they are likely represented behind the scenes as numeric objects (so something like “1.00” or “2.00”). This isn’t important most of the time…except when it is.

If you explicitly want an integer, you need to specify the L suffix. So entering 1 in R gives you a numeric object; entering 1L explicitly gives you an integer object.

There is also a special number Inf which represents infinity. This allows us to represent entities like 1 / 0. This way, Inf can be used in ordinary calculations; e.g. 1 / Inf is 0.

The value NaN represents an undefined value (“not a number”); e.g. 0 / 0; NaN can also be thought of as a missing value (more on that later)

### 1.3 Attributes

R objects can have attributes, which are like metadata for the object. These metadata can be very useful in that they help to describe the object. For example, column names on a data frame help to tell us what data are contained in each of the columns. Some examples of R object attributes are

- names, dimnames
- dimensions (e.g. matrices, arrays)
- class (e.g. integer, numeric)
- length
- other user-defined attributes/metadata

Attributes of an object (if any) can be accessed using the attributes() function. Not all R objects contain attributes, in which case the attributes() function returns NULL.

### Creating Vectors

The c() function can be used to create vectors of objects by concatenating things together.

```{r}
x <- c(0.5, 0.6) # Numeric
x <- c(TRUE, FALSE) # Logical
x <- c(T, F) # Logical
x <- c("a", "b", "c") # Character
x <- 9:29 # Integer
x <- c(1+0i, 2+4i) # Complex
```

You can also use the vector() function to initialize vectors.

```{r}
x <- vector("numeric", length = 10)
x
```

### 1.4 Mixing Objects

There are occasions when different classes of R objects get mixed together.

```{r}
y <- c(1.7, "a") # Character
y <- c(TRUE, 2) # Numeric
y <- c("a", TRUE) # Character
```

In each case above, we are mixing objects of two different classes in a vector. But remember that the only rule about vectors says this is not allowed. When different objects are mixed in a vector, coercion occurs so that every element in the vector is of the same class.

In the example above, we see the effect of implicit coercion. What R tries to do is find a way to represent all of the objects in the vector in a reasonable fashion. Sometimes this does exactly what you want and…sometimes not. For example, combining a numeric object with a character object will create a character vector, because numbers can usually be easily represented as strings.

### 1.5 Explicit Coercion

Objects can be explicitly coerced from one class to another using the as.* functions, if available.

```{r}
x <- 0.6
class(x)

as.numeric(x)

as.logical(x)

as.character(x)
```

Sometimes, R can’t figure out how to coerce an object and this can result in NAs being produced.

```{r}
x <- c("a", "b", "c")

as.numeric(x)

as.logical(x)

as.complex(x)
```

### Matrices

Matrices are vectors with a dimension attribute. The dimension attribute is itself an integer vector of length 2 (number of rows, number of columns)

```{r}
m <- matrix(nrow = 2, ncol = 3)
m

dim(m)

attributes(m)
```

Matrices are constructed column-wise, so entries can be thought of starting in the “upper left” corner and running down the columns.

```{r}
m <- matrix(1:6, nrow = 2, ncol = 3)
m
```

Matrices can also be created directly from vectors by adding a dimension attribute.

```{r}
m <- 1:10
m

dim(m) <- c(2, 5)
m
```

Matrices can be created by column-binding or row-binding with the cbind() and rbind() functions.

```{r}
x <- 1:3
y <- 10:12

cbind(x, y)

rbind(x, y)
```

### 1.5 Lists

Lists are a special type of vector that can contain elements of different classes. Lists are a very important data type in R and you should get to know them well. Lists, in combination with the various “apply” functions discussed later, make for a powerful combination.

Lists can be explicitly created using the list() function, which takes an arbitrary number of arguments.

```{r}
x <- list(1, "a", TRUE, 1 +4i)
x
```

We can also create an empty list of a prespecified length with the vector() function

```{r}
x <- vector("list", length = 5)
x
```

### 1.6 Factors

Factors are used to represent categorical data and can be unordered or ordered. One can think of a factor as an integer vector where each integer has a label. Factors are important in statistical modeling and are treated specially by modelling functions like lm() and glm().

Using factors with labels is better than using integers because factors are self-describing. Having a variable that has values “Male” and “Female” is better than a variable that has values 1 and 2.

Factor objects can be created with the factor() function.

```{r}
x <- factor(c("yes", "yes", "no", "yes", "no"))
x

table(x)

## See the underlying representation of factor
unclass(x)

attr(x, "levels")
```

Often factors will be automatically created for you when you read a dataset in using a function like read.table(). Those functions often default to creating factors when they encounter data that look like characters or strings.

The order of the levels of a factor can be set using the levels argument to factor(). This can be important in linear modelling because the first level is used as the baseline level.

```{r}
x <- factor(c("yes", "yes", "no", "yes", "no"))
x

## Levels are put in alphabetical order
x <- factor(c("yes", "yes", "no", "yes", "no"),
            levels = c("yes", "no"))
x
```

### 1.7 Missing Values

Missing values are denoted by NA or NaN for q undefined mathematical operations.

- is.na() is used to test objects if they are NA
- is.nan() is used to test for NaN
- NA values have a class also, so there are integer NA, character NA, etc.
- A NaN value is also NA but the converse is not true

```{r}
## Create a vector with NAs in it
x <- c(1, 2, NA, 10, 3)

## Return a logical vector indicating which elements are NA
is.na(x)

## Return a logical vector indicating which elements are NaN
is.nan(x)
```

```{r}
## Now create a vector with both NA and NaN values
x <- c(1, 2, NaN, NA, 4)

is.na(x)

is.nan(x)
```

### 1.8 Data Frames

Data frames are represented as a special type of list where every element of the list has to have the same length. Each element of the list can be thought of as a column and the length of each element of the list is the number of rows.

Unlike matrices, data frames can store different classes of objects in each column. Matrices must have every element be the same class (e.g. all integers or all numeric).

In addition to column names, indicating the names of the variables or predictors, data frames have a special attribute called row.names which indicate information about each row of the data frame.

Data frames are usually created by reading in a dataset using the read.table() or read.csv(). However, data frames can also be created explicitly with the data.frame() function or they can be coerced from other types of objects like lists.

Data frames can be converted to a matrix by calling data.matrix(). While it might seem that the as.matrix() function should be used to coerce a data frame to a matrix, almost always, what you want is the result of data.matrix().

```{r}
x <- data.frame(foo = 1:4,
                bar = c(T, T, F, F))
x

nrow(x)

ncol(x)
```

### 1.9 Names

R objects can have names, which is very useful for writing readable code and self-describing objects. Here is an example of assigning names to an integer vector.

```{r}
x <- 1:3
names(x)

names(x) <- c("NW", "SA", "LA")
x

names(x)
```

Lists can also have names, which is often very useful.

```{r}
x <- list("LA" = 1, Boston = 2, "London" = 3)
x

names(x)
```

Matrices can have both column and row names.

```{r}
m <- matrix(1:4, nrow = 2, ncol = 2)
dimnames(m) <- list(c("a", "b"), # Row names
                    c("c", "d")) # Col names
```

Column names and row names can be set separately using the colnames() and rownames() functions.

```{r}
colnames(m) <- c("h", "f")
rownames(m) <- c("x", "z")
```

Note that for data frames, there is a separate function for setting the row names, the row.names() function. Also, data frames do not have column names, they just have names (like lists). So to set the column names of a data frame just use the names() function. Yes, I know its confusing. Here’s a quick summary:

Object: data frame | Set column names: names() | Set row names: row.names() <br>
Object: Matrix | Set column names: colnames() | Set row names: rownames()

### 1.10 Summary 

There are a variety of different builtin-data types in R. In this chapter we have reviewed the following

- atomic classes: numeric, logical, character, integer, complex
- vectors, lists
- factors
- missing values
- data frames and matrices

All R objects can have attributes that help to describe what is in the object. Perhaps the most useful attribute is names, such as column and row names in a data frame, or simply names in a vector or list. Attributes like dimensions are also important as they can modify the behavior of objects, like turning a vector into a matrix.

## 2. Getting Data in and Out of R

### 2.1 Reading and Writing Data

There are a few principal functions reading data into R.

- read.table, read.csv, for reading tabular data
- readLines, for reading lines of a text file
- source, for reading in R code files (inverse of dump)
- dget, for reading in R code files (inverse of dput)
- load, for reading in saved workspaces
- unserialize, for reading single R objects in binary form

There are of course, many R packages that have been developed to read in all kinds of other datasets, and you may need to resort to one of these packages if you are working in a specific area.

There are analogous functions for writing data to files

- write.table, for writing tabular data to text files (i.e. CSV) or connections
- writeLines, for writing character data line-by-line to a file or connection
-dump, for dumping a textual representation of multiple R objects
- dput, for outputting a textual representation of an R object
- save, for saving an arbitrary number of R objects in binary format (possibly compressed) to a file.
- serialize, for converting an R object into a binary format for outputting to a connection (or file).

The read.table() function has a few important arguments:

- file, the name of a file, or a connection
- header, logical indicating if the file has a header line
- sep, a string indicating how the columns are separated
- colClasses, a character vector indicating the class of each column in the dataset
- nrows, the number of rows in the dataset. By default read.table() reads an entire file.
- comment.char, a character string indicating the comment character. This defalts to "#". If there are no commented lines in your file, it’s worth setting this to be the empty string "".
- skip, the number of lines to skip from the beginning
- stringsAsFactors, should character variables be coded as factors? This defaults to TRUE because back in the old days, if you had data that were stored as strings, it was because those strings represented levels of a categorical variable. Now we have lots of data that is text data and they don’t always represent categorical variables. So you may want to set this to be FALSE in those cases. If you always want this to be FALSE, you can set a global option via options(stringsAsFactors = FALSE). I’ve never seen so much heat generated on discussion forums about an R function argument than the stringsAsFactors argument. Seriously.

Telling R all these things directly makes R run faster and more efficiently. The read.csv() function is identical to read.table except that some of the defaults are set differently (like the sep argument).

### 2.2 Reading in Larger Datasets with read.table

With much larger datasets, there are a few things that you can do that will make your life easier and will prevent R from choking.

- Read the help page for read.table, which contains many hints

- Make a rough calculation of the memory required to store your dataset (see the next section for an example of how to do this). If the dataset is larger than the amount of RAM on your computer, you can probably stop right here.

- Set comment.char = "" if there are no commented lines in your file.

- Use the colClasses argument. Specifying this option instead of using the default can make ’read.table’ run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are “numeric”, for example, then you can just set colClasses = "numeric". A quick an dirty way to figure out the classes of each column is the following:

```{r, eval = FALSE}
initial <- read.table("datatable.txt", nrow = 100)
classes <- sapply(initial, class)
tabAll <- read.table("datatable.txt", colClasses = classes)
```

- Set nrows. This doesn’t make R run faster but it helps with memory usage. A mild overestimate is okay. You can use the Unix tool wc to calculate the number of lines in a file.

## 3. Using the readr Package

he readr package is recently developed by Hadley Wickham to deal with reading in large flat files quickly. The package provides replacements for functions like read.table() and read.csv(). The analogous functions in readr are read_table() and read_csv(). These functions are often much faster than their base R analogues and provide a few other nice features such as progress meters.

For the most part, you can read use read_table() and read_csv() pretty much anywhere you might use read.table() and read.csv(). In addition, if there are non-fatal problems that occur while reading in the data, you will get a warning and the returned data frame will have some information about which rows/observations triggered the warning. This can be very helpful for “debugging” problems with your data before you get neck deep in data analysis.

The importance of the read_csv function is perhaps better understood from an historical perspective. R’s built in read.csv function similarly reads CSV files, but the read_csv function in readr builds on that by removing some of the quirks and “gotchas” of read.csv as well as dramatically optimizing the speed with which it can read data into R. The read_csv function also adds some nice user-oriented features like a progress meter and a compact method for specifying column types.

A typical call to read_csv will look as follows.

```{r, eval = FALSE}
library(readr)
teams <- read_csv("data/team_standings.csv")
```

By default, read_csv will open a CSV file and read it in line-by-line. It will also (by default), read in the first few rows of the table in order to figure out the type of each column (i.e. integer, character, etc.). From the read_csv help page:

If ‘NULL’, all column types will be imputed from the first 1000 rows on the input. This is convenient (and fast), but not robust. If the imputation fails, you’ll need to supply the correct types yourself.

You can specify the type of each column with the col_types argument.

In general, it’s a good idea to specify the column types explicitly. This rules out any possible guessing errors on the part of read_csv. Also, specifying the column types explicitly provides a useful safety check in case anything about the dataset should change without you knowing about it.

```{r, eval = FALSE}
library(readr)
teams <- read_csv("data/team_standings.csv", col_types = "cc") # First and second column are Charecters
```

Note that the col_types argument accepts a compact representation. Here "cc" indicates that the first column is character and the second column is character (there are only two columns). Using the col_types argument is useful because often it is not easy to automatically figure out the type of a column by looking at a few rows (especially if a column has many missing values).

The read_csv function will also read compressed files automatically. There is no need to decompress the file first or use the gzfile connection function. The following call reads a gzip-compressed CSV file containing download logs from the RStudio CRAN mirror.

```{r, eval = FALSE}
logs <- read_csv("data/2016-07-19.csv.bz2", n_max = 10)
```

Note that the warnings indicate that read_csv may have had some difficulty identifying the type of each column. This can be solved by using the col_types argument.

```{r, eval = FALSE}
logs <- read.csv("data/2016-07-19.csv.bz2", col_types = "ccicccccci", n_max = 10)
```

You can specify the column type in a more detailed fashion by using the various col_* functions. For example, in the log data above, the first column is actually a date, so it might make more sense to read it in as a Date variable. If we wanted to just read in that first column, we could do

```{r, eval = FALSE}
logdates <- read_csv("data/2016-07-19.csv.bz2",
                     col_types = cols_only(date = col_date()),
                     n_max = 10)
```

Now the date column is stored as a Date object which can be used for relevant date-related computations

## 4. Using Textual and Binary Formats for Storing Data

There are a variety of ways that data can be stored, including structured text files like CSV or tab-delimited, or more complex binary formats. However, there is an intermediate format that is textual, but not as simple as something like CSV. The format is native to R and is somewhat readable because of its textual nature.

One can create a more descriptive representation of an R object by using the dput() or dump() functions. The dump() and dput() functions are useful because the resulting textual format is edit-able, and in the case of corruption, potentially recoverable. Unlike writing out a table or CSV file, dump() and dput() preserve the metadata (sacrificing some readability), so that another user doesn’t have to specify it all over again. For example, we can preserve the class of each column of a table or the levels of a factor variable.

Textual formats can work much better with version control programs like subversion or git which can only track changes meaningfully in text files. In addition, textual formats can be longer-lived; if there is corruption somewhere in the file, it can be easier to fix the problem because one can just open the file in an editor and look at it (although this would probably only be done in a worst case scenario!). Finally, textual formats adhere to the Unix philosophy, if that means anything to you.

There are a few downsides to using these intermediate textual formats. The format is not very space-efficient, because all of the metadata is specified. Also, it is really only partially readable. In some instances it might be preferable to have data stored in a CSV file and then have a separate code file that specifies the metadata.

### 4.1 Using dput() and dump()

One way to pass data around is by deparsing the R object with dput() and reading it back in (parsing it) using dget().

```{r}
y <- data.frame(a = 1,
                b = "a")

# Prind dput output to consolde
dput(y)
```

Notice that the dput() output is in the form of R code and that it preserves metadata like the class of the object, the row names, and the column names.

The output of dput() can also be saved directly to a file.

```{r}
## Send dput output to a file
dput(y, file = "y.R")

## Read in dput output from a file
new.y <- dget("y.R")
```

Multiple objects can be deparsed at once using the dump function and read back in using source.

```{r}
x <- "foo"
y <- data.frame(a = 1L,
                b = "a")
```

We can dump() R objects to a file by passing a character vector of their names.

```{r}
dump(c("x", "y"), file = "data.R")
rm(x, y)
```

The inverse of dump() is source().

```{r}
source("data.R")
str(y)
```

### 4.2 Binary Formats

The complement to the textual format is the binary format, which is sometimes necessary to use for efficiency purposes, or because there’s just no useful way to represent data in a textual manner. Also, with numeric data, one can often lose precision when converting to and from a textual format, so it’s better to stick with a binary format.

The key functions for converting R objects into a binary format are save(), save.image(), and serialize(). Individual R objects can be saved to a file using the save() function.

```{r}
a <- data.frame(x = rnorm(100),
                y = runif(100))
b <- c(3, 4.4, 1/3)

# Save `a` and `b` to a file
save(a, b, file = "mydata.rda")

# Load `a` and `b` into your workspace
load("mydata.rda")
```

If you have a lot of objects that you want to save to a file, you can save all objects in your workspace using the save.image() function.

```{r}
# Save everything to a file
save.image(file = "mydata.RData")

# Load all objects in this file
load("mydata.RData")
```

Notice that I’ve used the .rda extension when using save() and the .RData extension when using save.image(). This is just my personal preference; you can use whatever file extension you want. The save() and save.image() functions do not care. However, .rda and .RData are fairly common extensions and you may want to use them because they are recognized by other software.

The serialize() function is used to convert individual R objects into a binary format that can be communicated across an arbitrary connection. This may get sent to a file, but it could get sent over a network or other connection.

When you call serialize() on an R object, the output will be a raw vector coded in hexadecimal format.

```{r}
x <- list(1, 2, 3)
serialize(x, NULL)
```

The benefit of the serialize() function is that it is the only way to perfectly represent an R object in an exportable format, without losing precision or any metadata. If that is what you need, then serialize() is the function for you.

## 5. Interfaces to the Outside World

Data are read in using connection interfaces. Connections can be made to files (most common) or to other more exotic things.

- file, opens a connection to a file
- gzfile, opens a connection to a file compressed with gzip
- bzfile, opens a connection to a file compressed with bzip2
- url, opens a connection to a webpage

In general, connections are powerful tools that let you navigate files or other external objects. Connections can be thought of as a translator that lets you talk to objects that are outside of R. Those outside objects could be anything from a data base, a simple text file, or a a web service API. Connections allow R functions to talk to all these different external objects without you having to write custom code for each object.

### 5.1 File Connections

Connections to text files can be created with the file() function.

```{r}
str(file)
```

The file() function has a number of arguments that are common to many other connection functions so it’s worth going into a little detail here.

- description is the name of the file
- open is a code indicating what mode the file should be opened in

The open argument allows for the following options:

- “r” open file in read only mode
- “w” open a file for writing (and initializing a new file)
- “a” open a file for appending
- “rb”, “wb”, “ab” reading, writing, or appending in binary mode (Windows)

In practice, we often don’t need to deal with the connection interface directly as many functions for reading and writing data just deal with it in the background.

For example, if one were to explicitly use connections to read a CSV file in to R, it might look like this

```{r, eval = FALSE}
## Create a connection to 'foo.txt'
con <- file("foo.txt")

## Open connection to 'foo.txt' in read-only mode
open(con, "r")

## Read from the connection
data <- read.csv(con)

## Close the connection
close(con)
```

which is the same as

```{r, eval = FALSE}
data <- read.csv("foo.txt")
```

The above example shows the basic approach to using connections. Connections must be opened, then the are read from or written to, and then they are closed.

### Reading Lines of a Text File

Text files can be read line by line using the readLines() function. This function is useful for reading text files that may be unstructured or contain non-standard data.

```{r, eval = FALSE}
## Open connection to gz-compressed text file
con <- gzfile("words.gz")
x <- readLines(con, 10)
x
```

For more structured text data like CSV files or tab-delimited files, there are other functions like read.csv() or read.table().

The above example used the gzfile() function which is used to create a connection to files compressed using the gzip algorithm. This approach is useful because it allows you to read from a file without having to uncompress the file first, which would be a waste of space and time.

There is a complementary function writeLines() that takes a character vector and writes each element of the vector one line at a time to a text file.

### 5.2 Reading From a URL connection

The readLines() function can be useful for reading in lines of webpages. Since web pages are basically text files that are stored on a remote server, there is conceptually not much difference between a web page and a local text file. However, we need R to negotiate the communication between your computer and the web server. This is what the url() function can do for you, by creating a url connection to a web server.

This code might take time depending on your connection speed.

```{r, eval = FALSE}
## Open a URL connection for reading
con <- url("https//www.jhu.edu", "r")

## Read the webpage
x <- readLines(con)

## Print out the first few lines
head(x)
```

We can use URL connection to read in specific data files that are stored on web servers.

## 6. Subsetting R Objects

There are three operators that can be used to extract subsets of R objects.

- The [ operator always returns an object of the same class as the original. It can be used to select multiple elements of an object

- The [[ operator is used to extract elements of a list or a data frame. It can only be used to extract a single element and the class of the returned object will not necessarily be a list or data frame.

- The $ operator is used to extract elements of a list or data frame by literal name. Its semantics are similar to that of [[.

### 6.1 Subsetting a vector

Vectors are basic objects in R and they can be subsetted using the [ operator.

```{r}
x <- c("a", "b", "c", "d", "e", "a")
x[1] ## Extract the first element
x[2] ## Extract the second element
```

The [ operator can be used to extract multiple elements of a vector by passing the operator an integer sequence. Here we extract the first four elements of the vector.

```{r}
x[1:4]
```

The sequence does not have to be in order; you can specify any arbitrary integer vector.

```{r}
x[c(1, 3, 4)]
```

We can also pass a logical sequence to the [ operator to extract elements of a vector that satisfy a given condition. For example, here we want the elements of x that come lexicographically after the letter “a”.

```{r}
u <- x > "a"
x[u]
```

Another, more compact, way to do this would be to skip the creation of a logical vector and just subset the vector directly with the logical expression.

```{r}
x[x > "a"]
```

### 7.2 Subsetting a Matrix

Matrices can be subsetted in the usual way with (i,j) type indices. Here, we create simple 2×3 matrix with the matrix function.

```{r}
x <- matrix(1:6, ncol = 3, nrow = 2)
x
```

We can access the (1,2) or the (2,1) element of this matrix using the appropriate indices.

```{r}
x[1,2]
x[2,1]
```

Indices can also be missing. This behavior is used to access entire rows or columns of a matrix.

```{r}
x[1, ]
x[2, ]
```

#### 7.2.1 Dropping matrix

By default, when a single element of a matrix is retrieved, it is returned as a vector of length 1 rather than a 1×1 matrix. Often, this is exactly what we want, but this behavior can be turned off by setting drop = FALSE

```{r}
x <- matrix(1:6, 2, 3)
x[1,2]
x[1,2, drop = FALSE]
x
```

Similarly, when we extract a single row or column of a matrix, R by default drops the dimension of length 1, so instead of getting a  1×3 matrix after extracting the first row, we get a vector of length 3. This behavior can similarly be turned off with the drop = FALSE option.

```{r}
x <- matrix(1:6, 2, 3)
x[1, ]
x[1, ,drop = FALSE]
```

Be careful of R’s automatic dropping of dimensions. This is a feature that is often quite useful during interactive work, but can later come back to bite you when you are writing longer programs or functions.

### 7.3 Subsetting Lists

Lists in R can be subsetted using all three of the operators mentioned above, and all three are used for different purposes.

```{r}
x <- list(foo = 1:4, bar = 0.6)
x
```

The [[ operator can be used to extract single elements from a list. Here we extract the first element of the list.

```{r}
x[[1]]
```

The [[ operator can also use named indices so that you don’t have to remember the exact ordering of every element of the list. You can also use the $ operator to extract elements by name.

```{r}
x[["bar"]]
x$bar
```

Notice you don’t need the quotes when you use the $ operator.

One thing that differentiates the [[ operator from the $ is that the [[ operator can be used with computed indices. The $ operator can only be used with literal names.

```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "Hello")
name <- "foo"

## Computed index for foo
x[[name]]

## Element name dosen`t exist! (But no error here)
x$name

## Element "foo" does exist
x$foo
```

### 7.4 Subsetting Nestes Elements of a List

The [[ operator can take an integer sequence if you want to extract a nested element of a list.

```{r}
x <- list(a = list(10, 12, 14),
          b = c(3.14, 2.81))

## Get the 3rd element of the 1 element
x[[c(1, 3)]]

## Same as above
x[[1]][[3]]

## 1st element of the 2nd element
x[[c(2, 1)]]

## Same as above
x[[2]][[1]]
```

### 7.5 Extracting Multiple Elements of a List

The [ operator can be used to extract multiple elements from a list. For example, if you wanted to extract the first and third elements of a list, you would do the following

```{r}
x <- list(foo = 1:4, 
          bar = 0.6,
          baz = "Hello")
x[c(1, 3)]

```

Note that

```{r}
# This is not the same
x[c(1, 3)]

# As this
x[[c(1, 3)]]
```

Remember that the [ operator always returns an object of the same class as the original. Since the original object was a list, the [ operator returns a list. In the above code, we returned a list with two elements (the first and the third).

### 7.6 Partial Matching

Partial matching of names is allowed with [[ and $. This is often very useful during interactive work if the object you’re working with has very long element names. You can just abbreviate those names and R will figure out what element you’re referring to.

```{r}
x <- list(aardvark = 1:5)
x$a

x[["a"]]
```

```{r, eval = FALSE}
x[["a", extract = FALSE]]
```

In general, this is fine for interactive work, but you shouldn’t resort to partial matching if you are writing longer scripts, functions, or programs. In those cases, you should refer to the full element name if possible. That way there’s no ambiguity in your code.

### 7.7 Removing NA Values

A common task in data analysis is removing missing values (NAs).

```{r}
x <- c(1, 2, NA, 4, NA, 5)
bad <- is.na(x)
print(bad)
x[!bad]
```

What if there are multiple R objects and you want to take the subset with no missing values in any of those objects?

```{r}
x <- c(1, 2, NA, 4, NA, 5)
y <- c("a", "b", NA, "d", NA, "f")
good <- complete.cases(x, y)
good
x[good]
y[good]
```

You can use complete.cases on data frames too.

```{r}
head(airquality)

good <- complete.cases(airquality)
head(airquality[good, ])
```

## 8. Vecotirez operations

Many operations in R are vectorized, meaning that operations occur in parallel in certain R objects. This allows you to write code that is efficient, concise, and easier to read than in non-vectorized languages.

The simplest example is when adding two vectors together.

```{r}
x <- 1:4
y <- 6:9
z <- x + y
z
```

Natural, right? Without vectorization, you’d have to do something like

```{r}
z <- numeric(length(x))
for(i in seq_along(x)) {
  z[i] <- x[i] + y[i]
}
z
```

Another operation you can do in a vectorized manner is logical comparisons. So suppose you wanted to know which elements of a vector were greater than 2. You could do he following

```{r}
x
x > 2
x >= 2
x < 3
y == 8
```

Notice that these logical operations return a logical vector of TRUE and FALSE.

Of course, subtraction, multiplication and division are also vectorized.

```{r}
x - y
x * y
x / y
```

### 8.1 Vectorized Matrix Operations

Matrix operations are also vectorized, making for nicly compact notation. This way, we can do element-by-element operations on matrices without having to loop over every element.

```{r}
x <- matrix(1:4, 2, 2)
y <- matrix(rep(10, 4), 2, 2)

x
y
## Element wise multiplication
x * y

## Element wise division
x / y

## True matrix multiplication
x %*% y
```

## Exercises

Exercise 1: Using dput and dump<br>
a) Create a numeric vector with random values and use dput to save it into a file named "my_vector.R".<br>
b) Create a data frame with random values and use dump to save it into a file named "my_data.R".<br>

```{r, eval = FALSE}
## A
my_vector <- c(1, 2, 3.2)
dput(my_vector, 
     file = "my.vector.R")

## B
my_df <- data.frame(A = c(1, 2, 3.2),
                    B = c(2, 3, 2.2))

dump(my_df, 
     file = "my_df.R")
```


Exercise 2: Subsetting Vectors and Removing NAs<br>
a) Create a numeric vector with some NA values.<br>
b) Use subsetting to extract the elements of the vector that are not NA.<br>
c) Calculate the mean of the non-NA elements.<br>

```{r}
## A
my_vector2 <- c(1, 2, 3, NA, 2, NA)

## B
vector_na <- is.na(my_vector2)
my_vector2[!vector_na]

vector_na2 <- complete.cases(my_vector2)
my_vector2[vector_na2]

## C
mean(!is.na(my_vector2))
mean(my_vector2[!vector_na])
mean(my_vector2[vector_na2])
```


Exercise 3: Subsetting Matrices and Removing NAs<br>
a) Create a matrix with some NA values in different rows and columns.<br>
b) Use subsetting to extract the rows and columns that do not contain any NA values.<br>

```{r}
## A
my_matrix <- matrix(c(1:5, NA, 7, NA, NA), 3, 3)
my_matrix

## B
na_matrix <- complete.cases(my_matrix)
na_matrix

my_matrix[na_matrix, ]
my_matrix[, na_matrix]
```


Exercise 4: Subsetting Lists and Removing NAs <br>
a) Create a list with multiple elements, including some NA values.<br>
b) Use subsetting to extract the elements that are not NA.<br>

```{r}
my_list <- list(letters = c("a", "b", NA, "c", NA),
                numbers = c(1, NA, 3, 4, NA))

na_list <- complete.cases(my_list)
na_list

my_list[[1]][na_list]
my_list[[2]][na_list]
my_list[[c(1, 2)]]
my_list[[1]][[2]]
```


Exercise 5: Subsetting Data Frames and Removing NAs<br>
a) Create a data frame with some NA values in different columns.<br>
b) Use subsetting to extract rows where all columns have non-NA values.<br>

```{r}
my_df <- data.frame(numbers = c(2.2, 1, NA, 3, NA),
                    letters = c("a", NA, NA, "c", "d"),
                    rambom = c(1, 2, 3, 4, 5))
my_df

my_df<- my_df[complete.cases(my_df), ]
```

## 9. Dates and Times

R has developed a special representation for dates and times. Dates are represented by the Date class and times are represented by the POSIXct or the POSIXlt class. Dates are stored internally as the number of days since 1970-01-01 while times are stored internally as the number of seconds since 1970-01-01.

### 9.1 Date in R

Dates are represented by the Date class and can be coerced from a character string using the as.Date() function. This is a common way to end up with a Date object in R.

```{r}
## Coerce a Date object from character
x <- as.Date("1970-01-01")
x
```

You can see the internal representation of a Date object by using the unclass() function.

```{r}
unclass(x)
```

### 9.2 Times in R

Times are represented by the POSIXct or the POSIXlt class. POSIXct is just a very large integer under the hood. It use a useful class when you want to store times in something like a data frame. POSIXlt is a list underneath and it stores a bunch of other useful information like the day of the week, day of the year, month, day of the month. This is useful when you need that kind of information.

There are a number of generic functions that work on dates and times to help you extract pieces of dates and/or times.

- weekdays: give the day of the week
- months: give the month name
- quarters: give the quarter number (“Q1”, “Q2”, “Q3”, or “Q4”)

Times can be coerced from a character string using the as.POSIXlt or as.POSIXct function.

```{r}
x <- Sys.time()
x

class(x) ## POSIXct
```

The POSIXlt object contains some useful metadata.

```{r}
p <- as.POSIXlt(x)
names(unclass(p))

p$wday
```

You can also use the POSIXct format.

```{r}
x <- Sys.time()
x ## Already in POSIXct format

unclass(x) # Internal representation
```

```{r, eval = FALSE}
x$sec # Can`t do this with POSIXct
```

```{r}
p <- as.POSIXlt(x)
p$sec # Thats better
```

Finally, there is the strptime() function in case your dates are written in a different format. strptime() takes a character vector that has dates and times and converts them into to a POSIXlt object.

```{r}
datestring <- c("January 10, 2012, 10:40", "December 9, 2011 9:10")
x <- strptime(datestring, "%B %d, %Y %H:%M")
x
class(x)
```

The weird-looking symbols that start with the % symbol are the formatting strings for dates and times. I can never remember the formatting strings. Check ?strptime for details. It’s probably not worth memorizing this stuff.

### 9.3 Operations on Dates and Times

You can use mathematical operations on dates and times. Well, really just + and -. You can do comparisons too (i.e. ==, <=)

```{r}
x <- as.Date("2012-01-01")
y <- 2
x-y
```

```{r}
x <- as.POSIXlt(x)
x-y
```

The nice thing about the date/time classes is that they keep track of all the annoying things about dates and times, like leap years, leap seconds, daylight savings, and time zones.

Here’s an example where a leap year gets involved.

```{r}
x <- as.Date("2012-03-01")
y <- as.Date("2012-02-28")
x-y
```

Here’s an example where two different time zones are in play (unless you live in GMT timezone, in which case they will be the same!).

```{r}
## My local time zone
x <- as.POSIXct("2012-10-25 01:00:00")
y <- as.POSIXct("2012-10-25 60:00:00", tz = "GMT")
y-x
```

## 10. Managing Data Frame with the dplyr package

```{r}
library(gamair)
library(tidyverse)
data(chicago)
str(chicago)
chicago <- chicago %>%
  mutate(city = "chic")
```

### select()

The select() function can be used to select columns of a data frame that you want to focus on. Often you’ll have a large data frame containing “all” of the data, but any given analysis might only use a subset of variables or observations. The select() function allows you to get the few columns you might need.

```{r}
names(chicago)[1:3]
subset <- select(chicago, death:pm25median)
```

Note that the : normally cannot be used with names or strings, but inside the select() function you can use it to specify a range of variable names.

You can also omit variables using the select() function by using the negative sign. With select() you can do

```{r}
select(chicago, -(death:pm25median))
```

which indicates that we should include every variable except the variables death through pm25median The equivalent code in base R would be

```{r}
i <- match("death", names(chicago))
j <- match("pm25median", names(chicago))
head(chicago[, -(i:j)])
```

The select() function also allows a special syntax that allows you to specify variable names based on patterns. So, for example, if you wanted to keep every variable that ends with a “n”, we could do

```{r}
subset <- select(chicago, ends_with("n"))
str(subset)
```

Or if we wanted to keep every variable that starts with a “p”, we could do

```{r}
subset <- select(chicago, starts_with("p"))
str(subset)
```

### filter()

The filter() function is used to extract subsets of rows from a data frame. This function is similar to the existing subset() function in R but is quite a bit faster in my experience.

Suppose we wanted to extract the rows of the chicago data frame where the levels of tmpd are greater than 25 (which is a reasonably high level), we could do

```{r}
chic.f <- filter(chicago, tmpd > 25)
str(chic.f)
summary(chic.f$tmpd)
```

We can place an arbitrarily complex logical sequence inside of filter()

```{r}
chic.f <- filter(chicago, tmpd > 25 & death > 100)
str(chic.f)
```

### arrange()

The arrange() function is used to reorder rows of a data frame according to one of the variables/columns. Reordering rows of a data frame (while preserving corresponding order of other columns) is normally a pain to do in R.

Here we can order the rows of the data frame by date, so that the first row is the lowest death observation and the last row is the largest observation.

```{r}
chicago <- arrange(chicago, death)
head(chicago)
tail(chicago)
```

```{r}
chicago <- arrange(chicago, desc(death))
head(chicago)
tail(chicago)
```

### rename()

Renaming a variable in a data frame in R is surprisingly hard to do! The rename() function is designed to make this process easier.

```{r}
head(chicago[, 1:8], 4)
```

```{r}
chicago <- rename(chicago, pm25 = pm25median)
```

The syntax inside the rename() function is to have the new name on the left-hand side of the = sign and the old name on the right-hand side.

### mutate()

The mutate() function exists to compute transformations of variables in a data frame. Often, you want to create new variables that are derived from existing variables and mutate() provides a clean interface for doing that.

Here we create a pm25detrend variable that subtracts the mean from the pm25 variable.

```{r}
chicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))
```

There is also the related transmute() function, which does the same thing as mutate() but then drops all non-transformed variables.

```{r}
head(transmute(chicago,
               pm10detrend = pm10median - mean(pm10median, na.rm = TRUE),
               o3detrend = o3median - mean(o3median, na.rm = TRUE)))
```

### group_by()

The group_by() function is used to generate summary statistics from the data frame within strata defined by a variable. For example, in this air pollution dataset, you might want to know what the average annual level of PM2.5 is. So the stratum is the year, and that is something we can derive from the date variable. In conjunction with the group_by() function we often use the summarize() function (or summarise() for some parts of the world).

The general operation here is a combination of splitting a data frame into separate pieces defined by a variable or group of variables (group_by()), and then applying a summary function across those subsets (summarize()).

```{r}
days <- group_by(chicago, time)
summarize(days, pm25 = mean(pm25, na.rm = TRUE),
          o3median = max(o3median),
          .groups = "drop")
```

summarize() returns a data frame with days as the first column, and then the annual averages of pm25 and o3 max.

In a slightly more complicated example, we might want to know what are the average levels of ozone (o3) and nitrogen dioxide (no2) within quintiles of pm25. A slicker way to do this would be through a regression model, but we can actually do this quickly with group_by() and summarize().

```{r}
qq <- quantile(chicago$pm25,
               seq(0, 1, 0.2), 
               na.rm = TRUE)
chicago <- mutate(chicago, pm25.quint = cut(pm25, qq))
```

Now we can group the data frame by the pm25.quint variable.

```{r}
quint <- group_by(chicago, pm25.quint)
```

```{r}
summarize(quint, 
          o3 = mean(o3median, 
                    na.rm = TRUE),
          o2 = mean(so2median,
                    na.rm = TRUE),
          .groups = "drop")
```

The pipeline operater %>% is very handy for stringing together multiple dplyr functions in a sequence of operations. Notice above that every time we wanted to apply more than one function, the sequence gets buried in a sequence of nested function calls that is difficult to read, i.e.

```{r, eval = FALSE}
third(second(first(x)))
```

```{r, eval = FALSE}
first(x) %>%
  second %>%
  third
```

Take the example that we just did in the last section where we computed the mean of o3 and no2 within quintiles of pm25. There we had to

create a new variable pm25.quint
split the data frame by that new variable
compute the mean of o3 and no2 in the sub-groups defined by pm25.quint

```{r}
mutate(chicago, pm25.quint = cut(pm25, qq)) %>%
  group_by(pm25.quint) %>%
  summarize(o3 = mean(o3median, na.rm = TRUE),
            so2 = mean(so2median, na.rm = TRUE),
            .groups = "drop")
```

This way we don’t have to create a set of temporary variables along the way or create a massive nested sequence of function calls.

Notice in the above code that I pass the chicago data frame to the first call to mutate(), but then afterwards I do not have to pass the first argument to group_by() or summarize(). Once you travel down the pipeline with %>%, the first argument is taken to be the output of the previous element in the pipeline.

## Control Structures *

Control structures in R allow you to control the flow of execution of a series of R expressions. Basically, control structures allow you to put some “logic” into your R code, rather than just always executing the same R code every time. Control structures allow you to respond to inputs or to features of the data and execute different R expressions accordingly.

Commonly used control structures are

- if and else: testing a condition and acting on it
- for: execute a loop a fixed number of times
- while: execute a loop while a condition is true
- repeat: execute an infinite loop (must break out of it to stop)
- break: break the execution of a loop
- next: skip an interation of a loop

### if else

The if-else combination is probably the most commonly used control structure in R (or perhaps any language). This structure allows you to test a condition and act on it depending on whether it’s true or false.

```{r, eval = FALSE}
if(condition) {
  ## do something
} else {
  ## do something else
} else {
  ## do something else
}

## continue code
```

```{r}
## Generate a uniform random number
x <- runif(1, 0, 10)

if(x > 3) {
  y <- 10 
} else { 
  y <- 0
}
```

The value of y is set depending on whether x > 3 or not. This expression can also be written a different, but equivalent, way in R.

```{r}
y <- if(x > 3) {
  10
} else {
  0
}
```

Of course, the else clause is not necessary. You could have a series of if clauses that always get executed if their respective conditions are true.

```{r, eval = FALSE}
if(condition1) {
  
  
} 

if(condition2){ 
  
}
```

### for loops

For loops are pretty much the only looping construct that you will need in R. While you may occasionally find a need for other types of loops, in my experience doing data analysis, I’ve found very few situations where a for loop wasn’t sufficient.

In R, for loops take an interator variable and assign it successive values from a sequence or vector. For loops are most commonly used for iterating over the elements of an object (list, vector, etc.)

```{r}
for(i in 1:10) { 
  print(i)
}
```

This loop takes the i variable and in each iteration of the loop gives it values 1, 2, 3, …, 10, executes the code within the curly braces, and then the loop exits.

The following three loops all have the same behavior.

```{r}
x <- c("a", "b", "c", "d")

for(i in 1:4) {
  ## Print out each element of x
  print(x[i])
}
```

The seq_along() function is commonly used in conjunction with for loops in order to generate an integer sequence based on the length of an object (in this case, the object x).

```{r}
## Generate a sequence based on length of x
for(i in seq_along(x)) {
  print(x[i])
}
```

It is not necessary to use an index-type variable.

```{r}
for(letter in x) {
  print(letter)
}
```

For one line loops, the curly braces are not strictly necessary.

```{r}
for(i in 1:4) print(x[i])
```

### Nested for loops

for loops can be nested inside of each other.

```{r}
x <- matrix(1:6, 2, 3)

for(i in seq_len(nrow(x))) {
  for(j in seq_len(ncol(x))) {
    print(x[i, j])
  }
}
```

### while loops

While loops begin by testing a condition. If it is true, then they execute the loop body. Once the loop body is executed, the condition is tested again, and so forth, until the condition is false, after which the loop exits.

```{r}
count <- 0

while(count < 10) {
  print(count)
  count <- count +1
}
```

```{r}
z <- 5
set.seed(1)

while(z >= 3 && z <= 10) {
  coin <- rbinom(1, 1, 0.5)
  
  if(coin == 1) { ## Random walk
    z <- z +1
  } else {
    z <- z -1
  }
}
print(z)
```

Conditions are always evaluated from left to right. For example, in the above code, if z were less than 3, the second test would not have been evaluated.

### repeat loops

repeat initiates an infinite loop right from the start. These are not commonly used in statistical or data analysis applications but they do have their uses. The only way to exit a repeat loop is to call break.

One possible paradigm might be in an iterative algorith where you may be searching for a solution and you don’t want to stop until you’re close enough to the solution. In this kind of situation, you often don’t know in advance how many iterations it’s going to take to get “close enough” to the solution.

```{r, eval = FALSE}
x0 <- 1
tol <- 1e-8

repeat {
  x1 <- computeEstimate()
  
  if(abs(x1 - x0) < tol) { ## close enough?
    break
  } else {
      x0 <- x1
    }
}
```

### next, break

next is used to skip an iteration of a loop.

```{r}
for(i in 1:100) {
  if (i <= 20) {
    ## Skip the first 20 iterations
    next
  }
  ## Do something here
  if (i > 15) {
    break
  }
}
```

break is used to exit a loop immediately, regardless of what iteration the loop may be on.

```{r}
for (i in 1:100){
  print(i)
  
  if(i > 20) {
    ## Stop loop after 20 iterations
    break
  }
}
```

### Exercises for loops and if else

Exercise 1: Use a for loop to print the names of all columns in the mtcars dataframe.

```{r}
data(mtcars)
for (i in seq_along(mtcars)) {
  names <- colnames(mtcars[i])
  print(names)
}
```


Exercise 2: Use a for loop to calculate the mean of each column in the mtcars dataframe.

Exercise 3: Use a for loop to count how many cars in the mtcars dataframe have more than 100 horsepower (hp column).

Exercise 4: Use a while loop to print the unique values of the cyl column in the mtcars dataframe.

Exercise 5: Use a while loop to calculate the cumulative sum of the mpg column in the mtcars dataframe.

Exercise 6: Use if-else statements to create a new column in the mtcars dataframe called "fuel_efficiency," where cars with mpg greater than 20 are labeled "efficient" and others are labeled "inefficient."

Exercise 7: Use a for loop to print the names of columns in the mtcars dataframe, but skip printing the column "carb."

Exercise 8: Use a while loop to find the first car in the mtcars dataframe with more than 200 horsepower (hp column).

Exercise 9: Use if-else statements to create a new column in the mtcars dataframe called "high_power," where cars with more than 150 horsepower are labeled TRUE and others are labeled FALSE.

Exercise 10: Use a for loop to calculate the product of all values in the wt column of the mtcars dataframe.

Exercise 11: Use a while loop to print the names of columns in the mtcars dataframe until you encounter the column "qsec."

Exercise 12: Use if-else statements to create a new column in the mtcars dataframe called "gear_type," where cars with 4 gears are labeled "four_gears," with 3 gears are labeled "three_gears," and with 5 gears are labeled "five_gears."

Exercise 13: Use a for loop to calculate the mean of each row in the mtcars dataframe.

Exercise 14: Use a while loop to find the first car in the mtcars dataframe with more than 25 miles per gallon (mpg column).

Exercise 15: Use if-else statements to create a new column in the mtcars dataframe called "cyl_category," where cars with 4 cylinders are labeled "four_cylinder," with 6 cylinders are labeled "six_cylinder," and with 8 cylinders are labeled "eight_cylinder."